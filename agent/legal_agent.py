"""
æ³•å¾‹ç»´æƒæ™ºèƒ½Agent
æ ¸å¿ƒé—®ç­”é€»è¾‘ï¼Œæ•´åˆRAGå’ŒLLM API
"""
from typing import Optional
from datetime import datetime

from ..models import Answer, QuestionType
from ..config import Config
from .llm_factory import create_llm_client, LLMClientBase
from .prompt_templates import PromptTemplates
from .conversation_manager import ConversationManager
from ..knowledge import KnowledgeRetriever


class LegalAgent:
    """æ³•å¾‹ç»´æƒæ™ºèƒ½Agent"""

    def __init__(
        self,
        llm_client: Optional[LLMClientBase] = None,
        retriever: Optional[KnowledgeRetriever] = None,
        conversation_manager: Optional[ConversationManager] = None
    ):
        """
        åˆå§‹åŒ–Agent

        Args:
            llm_client: LLMå®¢æˆ·ç«¯ï¼ˆè‡ªåŠ¨é€‰æ‹©æˆ–æ‰‹åŠ¨æŒ‡å®šï¼‰
            retriever: çŸ¥è¯†æ£€ç´¢å™¨
            conversation_manager: å¯¹è¯ç®¡ç†å™¨
        """
        self.llm = llm_client or create_llm_client()
        self.retriever = retriever or KnowledgeRetriever(auto_load=True)
        self.conversation = conversation_manager or ConversationManager()
        self.templates = PromptTemplates()

    def ask(
        self,
        question: str,
        use_context: bool = True,
        top_k: int = None
    ) -> Answer:
        """
        å•æ¬¡é—®ç­”

        Args:
            question: ç”¨æˆ·é—®é¢˜
            use_context: æ˜¯å¦ä½¿ç”¨å¯¹è¯ä¸Šä¸‹æ–‡
            top_k: æ£€ç´¢æ–‡æ¡£æ•°é‡

        Returns:
            ç­”æ¡ˆå¯¹è±¡
        """
        top_k = top_k or Config.TOP_K_RESULTS

        print(f"\nğŸ¤” é—®é¢˜: {question}")
        print("-" * 70)

        # 1. åˆ†ç±»é—®é¢˜ç±»å‹
        print("ğŸ“‹ åˆ†æé—®é¢˜ç±»å‹...", end=" ")
        question_type = self._classify_question(question)
        print(f"âœ… {question_type.value}")

        # 2. æ£€ç´¢ç›¸å…³æ–‡æ¡£
        print(f"ğŸ” æ£€ç´¢ç›¸å…³æ–‡æ¡£ (Top-{top_k})...", end=" ")
        try:
            relevant_docs_with_scores = self.retriever.retrieve(
                query=question,
                top_k=top_k
            )
            relevant_docs = [doc for doc, score in relevant_docs_with_scores]
            scores = [score for doc, score in relevant_docs_with_scores]
            print(f"âœ… æ‰¾åˆ° {len(relevant_docs)} ä¸ªç›¸å…³æ–‡æ¡£")

            # æ˜¾ç¤ºç›¸å…³åº¦
            if relevant_docs:
                avg_score = sum(scores) / len(scores)
                print(f"   å¹³å‡ç›¸å…³åº¦: {avg_score:.4f}")

        except Exception as e:
            print(f"âš ï¸  æ£€ç´¢å¤±è´¥: {e}")
            relevant_docs = []
            scores = []

        # 3. æ„å»ºPrompt
        print("ğŸ’­ æ„å»ºæç¤ºè¯...", end=" ")

        if use_context and self.conversation.has_context():
            # å¤šè½®å¯¹è¯æ¨¡å¼
            history = self.conversation.get_conversation_history()
            prompt = self.templates.build_follow_up_prompt(
                previous_qa=history[-3:],  # æœ€è¿‘3è½®
                current_question=question
            )
        else:
            # RAGæ¨¡å¼
            prompt = self.templates.build_rag_prompt(
                question=question,
                context_documents=relevant_docs,
                question_type=question_type
            )

        print("âœ…")

        # 4. è°ƒç”¨Claudeç”Ÿæˆç­”æ¡ˆ
        print("ğŸ¤– ç”Ÿæˆå›ç­”...", end=" ")
        try:
            answer_text = self.llm.complete(
                prompt=prompt,
                system=self.templates.SYSTEM_ROLE,
                temperature=0.7
            )
            print("âœ…")
        except Exception as e:
            print(f"âŒ å¤±è´¥: {e}")
            answer_text = "æŠ±æ­‰ï¼Œæˆ‘é‡åˆ°äº†ä¸€äº›æŠ€æœ¯é—®é¢˜ï¼Œæ— æ³•ç”Ÿæˆå›ç­”ã€‚è¯·ç¨åå†è¯•ã€‚"

        # 5. è®¡ç®—ç½®ä¿¡åº¦
        confidence = self._calculate_confidence(scores, question_type)

        # 6. æå–æ¥æº
        sources = list(set(doc.source_url for doc in relevant_docs))

        # 7. åˆ›å»ºç­”æ¡ˆå¯¹è±¡
        answer = Answer(
            question=question,
            answer_text=answer_text,
            question_type=question_type,
            relevant_docs=relevant_docs,
            confidence=confidence,
            sources=sources,
            created_at=datetime.now()
        )

        # 8. ä¿å­˜åˆ°å¯¹è¯å†å²
        self.conversation.add_turn(question, answer)

        return answer

    def chat(self, question: str, top_k: int = None) -> Answer:
        """
        å¤šè½®å¯¹è¯ï¼ˆå¸¦ä¸Šä¸‹æ–‡ï¼‰

        Args:
            question: ç”¨æˆ·é—®é¢˜
            top_k: æ£€ç´¢æ–‡æ¡£æ•°é‡

        Returns:
            ç­”æ¡ˆå¯¹è±¡
        """
        return self.ask(question, use_context=True, top_k=top_k)

    def reset_conversation(self):
        """é‡ç½®å¯¹è¯å†å²"""
        self.conversation.reset()
        print("âœ… å¯¹è¯å†å²å·²é‡ç½®")

    def get_conversation_summary(self) -> str:
        """
        è·å–å¯¹è¯æ‘˜è¦

        Returns:
            å¯¹è¯æ‘˜è¦
        """
        return self.conversation.get_summary()

    def _classify_question(self, question: str) -> QuestionType:
        """
        åˆ†ç±»é—®é¢˜ç±»å‹

        Args:
            question: ç”¨æˆ·é—®é¢˜

        Returns:
            é—®é¢˜ç±»å‹
        """
        # ç®€å•çš„å…³é”®è¯åŒ¹é…
        question_lower = question.lower()

        # èµ”å¿è®¡ç®—
        if any(kw in question_lower for kw in ["è®¡ç®—", "å¤šå°‘é’±", "é‡‘é¢", "ç®—", "å‡ ä¸ªæœˆ"]):
            return QuestionType.CALCULATION

        # ç»´æƒæµç¨‹
        if any(kw in question_lower for kw in ["æ€ä¹ˆåŠ", "å¦‚ä½•", "æµç¨‹", "ä»²è£", "èµ·è¯‰", "ç»´æƒ"]):
            return QuestionType.PROCEDURE

        # æ³•å¾‹ä¾æ®
        if any(kw in question_lower for kw in ["æ³•å¾‹", "æ³•è§„", "è§„å®š", "ä¾æ®", "æ¡æ–‡"]):
            return QuestionType.LEGAL_BASIS

        # ç»æµè¡¥å¿
        if any(kw in question_lower for kw in ["è¡¥å¿", "èµ”å¿", "n+1", "2n"]):
            return QuestionType.COMPENSATION

        # é»˜è®¤ä¸ºä¸€èˆ¬å’¨è¯¢
        return QuestionType.GENERAL

    def _calculate_confidence(
        self,
        retrieval_scores: list[float],
        question_type: QuestionType
    ) -> float:
        """
        è®¡ç®—ç­”æ¡ˆç½®ä¿¡åº¦

        Args:
            retrieval_scores: æ£€ç´¢ç›¸å…³åº¦åˆ†æ•°
            question_type: é—®é¢˜ç±»å‹

        Returns:
            ç½®ä¿¡åº¦ï¼ˆ0-1ï¼‰
        """
        if not retrieval_scores:
            return 0.5  # æ— æ£€ç´¢ç»“æœï¼Œä¸­ç­‰ç½®ä¿¡åº¦

        # åŸºç¡€ç½®ä¿¡åº¦ = å¹³å‡æ£€ç´¢åˆ†æ•°
        avg_score = sum(retrieval_scores) / len(retrieval_scores)

        # æ ¹æ®é—®é¢˜ç±»å‹è°ƒæ•´
        type_weight = {
            QuestionType.LEGAL_BASIS: 1.0,  # æ³•å¾‹ä¾æ®æœ€å¯é 
            QuestionType.COMPENSATION: 0.9,
            QuestionType.CALCULATION: 0.85,
            QuestionType.PROCEDURE: 0.9,
            QuestionType.CASE_ANALYSIS: 0.8,
            QuestionType.GENERAL: 0.7
        }

        weight = type_weight.get(question_type, 0.8)
        confidence = avg_score * weight

        # é™åˆ¶åœ¨0-1èŒƒå›´
        return max(0.0, min(1.0, confidence))


def main():
    """æµ‹è¯•Legal Agent"""
    print("ğŸ§ª æµ‹è¯• Legal Agent")
    print("=" * 80)

    # æ£€æŸ¥é…ç½®
    if not Config.CLAUDE_API_KEY:
        print("âŒ è¯·å…ˆé…ç½® CLAUDE_API_KEY")
        return

    # æ£€æŸ¥ç´¢å¼•
    index_path = Config.VECTORS_DIR / "index.faiss"
    if not index_path.exists():
        print("âš ï¸  å‘é‡ç´¢å¼•ä¸å­˜åœ¨ï¼Œå°†ä½¿ç”¨ç©ºç´¢å¼•")
        print("   è¿è¡Œ python scripts/test_vector_index.py æ„å»ºç´¢å¼•")

    # åˆå§‹åŒ–Agent
    try:
        agent = LegalAgent()
        print("âœ… Agentåˆå§‹åŒ–æˆåŠŸ\n")
    except Exception as e:
        print(f"âŒ Agentåˆå§‹åŒ–å¤±è´¥: {e}")
        return

    # æµ‹è¯•é—®ç­”
    questions = [
        "å¦‚ä½•è®¡ç®—N+1ç»æµè¡¥å¿é‡‘ï¼Ÿ",
        "å…¬å¸æ¶æ„è¾é€€ä¸ç»™è¡¥å¿æ€ä¹ˆåŠï¼Ÿ",
        "åŠ³åŠ¨ä»²è£éœ€è¦å‡†å¤‡ä»€ä¹ˆææ–™ï¼Ÿ"
    ]

    for i, question in enumerate(questions, 1):
        print(f"\n{'='*80}")
        print(f"æµ‹è¯• {i}/{len(questions)}")
        print('='*80)

        try:
            answer = agent.ask(question)
            print(answer.display())
        except Exception as e:
            print(f"âŒ å›ç­”å¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

    # æ˜¾ç¤ºå¯¹è¯æ‘˜è¦
    print("\n" + "=" * 80)
    print("ğŸ“Š å¯¹è¯æ‘˜è¦")
    print("=" * 80)
    print(agent.get_conversation_summary())

    print("\nâœ… æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    main()
