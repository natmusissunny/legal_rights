"""
çŸ¥è¯†æ£€ç´¢å™¨
æä¾›é«˜çº§æ£€ç´¢åŠŸèƒ½ï¼ŒåŒ…æ‹¬é‡æ’åºå’Œç»“æœè¿‡æ»¤
"""
from typing import List, Optional
from pathlib import Path

from ..models import Document
from ..config import Config
from .vector_indexer import VectorIndexer
from .embedding_factory import create_embedding_client, EmbeddingClientBase


class KnowledgeRetriever:
    """çŸ¥è¯†æ£€ç´¢å™¨"""

    def __init__(
        self,
        indexer: Optional[VectorIndexer] = None,
        auto_load: bool = True
    ):
        """
        åˆå§‹åŒ–æ£€ç´¢å™¨

        Args:
            indexer: å‘é‡ç´¢å¼•å™¨
            auto_load: æ˜¯å¦è‡ªåŠ¨åŠ è½½ç´¢å¼•
        """
        if indexer is None:
            indexer = VectorIndexer()
            if auto_load:
                try:
                    indexer.load_index()
                except FileNotFoundError:
                    print("âš ï¸  ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨ï¼Œè¯·å…ˆæ„å»ºç´¢å¼•")

        self.indexer = indexer

    def retrieve(
        self,
        query: str,
        top_k: int = None,
        min_score: float = 0.0,
        filter_section: Optional[str] = None
    ) -> List[tuple[Document, float]]:
        """
        æ£€ç´¢ç›¸å…³æ–‡æ¡£

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›Top-Kç»“æœ
            min_score: æœ€å°ç›¸ä¼¼åº¦é˜ˆå€¼
            filter_section: è¿‡æ»¤ç‰¹å®šç« èŠ‚

        Returns:
            (æ–‡æ¡£, ç›¸ä¼¼åº¦) åˆ—è¡¨
        """
        top_k = top_k or Config.TOP_K_RESULTS

        # å‘é‡æ£€ç´¢
        results = self.indexer.search(query, top_k=top_k * 2)  # å¤šæ£€ç´¢ä¸€äº›ç”¨äºè¿‡æ»¤

        # è¿‡æ»¤ç»“æœ
        filtered_results = []
        for doc, score in results:
            # åˆ†æ•°è¿‡æ»¤
            if score < min_score:
                continue

            # ç« èŠ‚è¿‡æ»¤
            if filter_section and doc.section_title != filter_section:
                continue

            filtered_results.append((doc, score))

        # é™åˆ¶è¿”å›æ•°é‡
        return filtered_results[:top_k]

    def retrieve_with_context(
        self,
        query: str,
        top_k: int = None
    ) -> str:
        """
        æ£€ç´¢å¹¶ç»„åˆä¸ºä¸Šä¸‹æ–‡æ–‡æœ¬

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›Top-Kç»“æœ

        Returns:
            ç»„åˆçš„ä¸Šä¸‹æ–‡æ–‡æœ¬
        """
        results = self.retrieve(query, top_k=top_k)

        if not results:
            return ""

        context_parts = []
        for i, (doc, score) in enumerate(results, 1):
            section_info = f"[{doc.section_title}]" if doc.section_title else ""
            context_parts.append(
                f"### å‚è€ƒæ–‡æ¡£ {i} {section_info} (ç›¸å…³åº¦: {score:.2f})\n"
                f"{doc.content}\n"
            )

        return "\n".join(context_parts)

    def retrieve_by_keyword(
        self,
        keywords: List[str],
        top_k: int = None
    ) -> List[Document]:
        """
        å…³é”®è¯æ£€ç´¢ï¼ˆç®€å•çš„æ–‡æœ¬åŒ¹é…ï¼‰

        Args:
            keywords: å…³é”®è¯åˆ—è¡¨
            top_k: è¿”å›Top-Kç»“æœ

        Returns:
            æ–‡æ¡£åˆ—è¡¨
        """
        if not self.indexer.documents:
            return []

        top_k = top_k or Config.TOP_K_RESULTS

        # è®¡ç®—æ¯ä¸ªæ–‡æ¡£çš„å…³é”®è¯åŒ¹é…åˆ†æ•°
        doc_scores = []
        for doc in self.indexer.documents:
            content_lower = doc.content.lower()
            score = sum(1 for kw in keywords if kw.lower() in content_lower)

            if score > 0:
                doc_scores.append((doc, score))

        # æŒ‰åˆ†æ•°æ’åº
        doc_scores.sort(key=lambda x: x[1], reverse=True)

        # è¿”å›Top-K
        return [doc for doc, _ in doc_scores[:top_k]]

    def hybrid_retrieve(
        self,
        query: str,
        keywords: Optional[List[str]] = None,
        top_k: int = None,
        vector_weight: float = 0.7
    ) -> List[tuple[Document, float]]:
        """
        æ··åˆæ£€ç´¢ï¼ˆå‘é‡ + å…³é”®è¯ï¼‰

        Args:
            query: æŸ¥è¯¢æ–‡æœ¬
            keywords: å…³é”®è¯åˆ—è¡¨
            top_k: è¿”å›Top-Kç»“æœ
            vector_weight: å‘é‡æ£€ç´¢çš„æƒé‡ï¼ˆ0-1ï¼‰

        Returns:
            (æ–‡æ¡£, ç»¼åˆåˆ†æ•°) åˆ—è¡¨
        """
        top_k = top_k or Config.TOP_K_RESULTS
        keyword_weight = 1.0 - vector_weight

        # å‘é‡æ£€ç´¢
        vector_results = self.retrieve(query, top_k=top_k * 2)
        vector_scores = {doc.id: score for doc, score in vector_results}

        # å…³é”®è¯æ£€ç´¢
        keyword_scores = {}
        if keywords:
            keyword_results = self.retrieve_by_keyword(keywords, top_k=top_k * 2)
            max_kw_score = len(keywords)
            for doc in keyword_results:
                content_lower = doc.content.lower()
                score = sum(1 for kw in keywords if kw.lower() in content_lower)
                # å½’ä¸€åŒ–åˆ° 0-1
                keyword_scores[doc.id] = score / max_kw_score if max_kw_score > 0 else 0

        # åˆå¹¶åˆ†æ•°
        all_doc_ids = set(vector_scores.keys()) | set(keyword_scores.keys())
        combined_results = []

        for doc_id in all_doc_ids:
            v_score = vector_scores.get(doc_id, 0.0)
            k_score = keyword_scores.get(doc_id, 0.0)

            # è®¡ç®—ç»¼åˆåˆ†æ•°
            combined_score = vector_weight * v_score + keyword_weight * k_score

            # æ‰¾åˆ°å¯¹åº”çš„æ–‡æ¡£
            doc = None
            for d in self.indexer.documents:
                if d.id == doc_id:
                    doc = d
                    break

            if doc:
                combined_results.append((doc, combined_score))

        # æŒ‰ç»¼åˆåˆ†æ•°æ’åº
        combined_results.sort(key=lambda x: x[1], reverse=True)

        return combined_results[:top_k]

    def get_stats(self) -> dict:
        """
        è·å–æ£€ç´¢å™¨ç»Ÿè®¡ä¿¡æ¯

        Returns:
            ç»Ÿè®¡ä¿¡æ¯å­—å…¸
        """
        return self.indexer.get_stats()


def main():
    """æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª æµ‹è¯•çŸ¥è¯†æ£€ç´¢å™¨")
    print("=" * 70)

    # æ£€æŸ¥ç´¢å¼•æ˜¯å¦å­˜åœ¨
    index_path = Config.VECTORS_DIR / "index.faiss"
    if not index_path.exists():
        print("âŒ ç´¢å¼•ä¸å­˜åœ¨ï¼Œè¯·å…ˆè¿è¡Œ vector_indexer.py æ„å»ºç´¢å¼•")
        return

    # åˆå§‹åŒ–æ£€ç´¢å™¨
    retriever = KnowledgeRetriever(auto_load=True)

    # æµ‹è¯•å‘é‡æ£€ç´¢
    print("\n[æµ‹è¯•1] å‘é‡æ£€ç´¢")
    print("-" * 70)

    query = "å¦‚ä½•è®¡ç®—N+1ç»æµè¡¥å¿é‡‘ï¼Ÿ"
    print(f"æŸ¥è¯¢: {query}\n")

    results = retriever.retrieve(query, top_k=3)

    for i, (doc, score) in enumerate(results, 1):
        print(f"ç»“æœ {i} (ç›¸ä¼¼åº¦: {score:.4f})")
        print(f"ç« èŠ‚: {doc.section_title}")
        print(f"å†…å®¹: {doc.content[:150]}...")
        print()

    # æµ‹è¯•ä¸Šä¸‹æ–‡ç”Ÿæˆ
    print("\n[æµ‹è¯•2] ä¸Šä¸‹æ–‡ç”Ÿæˆ")
    print("-" * 70)

    context = retriever.retrieve_with_context(query, top_k=2)
    print(context[:500] + "...\n")

    # æµ‹è¯•å…³é”®è¯æ£€ç´¢
    print("\n[æµ‹è¯•3] å…³é”®è¯æ£€ç´¢")
    print("-" * 70)

    keywords = ["N+1", "è¡¥å¿é‡‘", "ä»£é€šçŸ¥é‡‘"]
    print(f"å…³é”®è¯: {keywords}\n")

    kw_results = retriever.retrieve_by_keyword(keywords, top_k=3)

    for i, doc in enumerate(kw_results, 1):
        print(f"ç»“æœ {i}")
        print(f"ç« èŠ‚: {doc.section_title}")
        print(f"å†…å®¹: {doc.content[:150]}...")
        print()

    # æµ‹è¯•æ··åˆæ£€ç´¢
    print("\n[æµ‹è¯•4] æ··åˆæ£€ç´¢")
    print("-" * 70)

    hybrid_results = retriever.hybrid_retrieve(
        query="ç»æµè¡¥å¿",
        keywords=["è¡¥å¿", "å·¥èµ„"],
        top_k=3
    )

    for i, (doc, score) in enumerate(hybrid_results, 1):
        print(f"ç»“æœ {i} (ç»¼åˆåˆ†æ•°: {score:.4f})")
        print(f"ç« èŠ‚: {doc.section_title}")
        print(f"å†…å®¹: {doc.content[:150]}...")
        print()

    print("=" * 70)
    print("âœ… æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    main()
