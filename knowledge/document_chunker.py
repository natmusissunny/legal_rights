"""
æ–‡æ¡£åˆ†å—å™¨
å°†é•¿æ–‡æœ¬åˆ†å‰²æˆå°å—ä»¥ä¾¿äºå‘é‡æ£€ç´¢
"""
from typing import List
import re

from ..models import Document, StructuredContent, LegalSection
from ..config import Config


class DocumentChunker:
    """æ–‡æ¡£åˆ†å—å™¨"""

    def __init__(
        self,
        chunk_size: int = None,
        chunk_overlap: int = None
    ):
        """
        åˆå§‹åŒ–åˆ†å—å™¨

        Args:
            chunk_size: åˆ†å—å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰
            chunk_overlap: é‡å å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰
        """
        self.chunk_size = chunk_size or Config.CHUNK_SIZE
        self.chunk_overlap = chunk_overlap or Config.CHUNK_OVERLAP

    def chunk_text(
        self,
        text: str,
        metadata: dict = None
    ) -> List[str]:
        """
        åˆ†å‰²æ–‡æœ¬

        Args:
            text: è¾“å…¥æ–‡æœ¬
            metadata: å…ƒæ•°æ®

        Returns:
            æ–‡æœ¬å—åˆ—è¡¨
        """
        if not text or not text.strip():
            return []

        # æ¸…ç†æ–‡æœ¬
        text = text.strip()

        # å¦‚æœæ–‡æœ¬çŸ­äºchunk_sizeï¼Œç›´æ¥è¿”å›
        if len(text) <= self.chunk_size:
            return [text]

        chunks = []
        start = 0

        while start < len(text):
            # è®¡ç®—ç»“æŸä½ç½®
            end = start + self.chunk_size

            # å¦‚æœä¸æ˜¯æœ€åä¸€å—ï¼Œå°è¯•åœ¨å¥å­è¾¹ç•Œåˆ†å‰²
            if end < len(text):
                # æŸ¥æ‰¾å¥å­ç»“æŸç¬¦
                sentence_ends = ['.', 'ã€‚', '!', 'ï¼', '?', 'ï¼Ÿ', '\n']
                best_end = end

                # åœ¨ chunk_size é™„è¿‘æŸ¥æ‰¾å¥å­è¾¹ç•Œ
                search_start = max(start + self.chunk_size // 2, start)
                search_end = min(end + 50, len(text))

                for i in range(end, search_start, -1):
                    if i < len(text) and text[i] in sentence_ends:
                        best_end = i + 1
                        break

                end = best_end

            # æå–å—
            chunk = text[start:end].strip()
            if chunk:
                chunks.append(chunk)

            # ä¸‹ä¸€å—çš„å¼€å§‹ä½ç½®ï¼ˆè€ƒè™‘é‡å ï¼‰
            start = end - self.chunk_overlap

            # é¿å…æ— é™å¾ªç¯
            if start <= end - self.chunk_size + self.chunk_overlap:
                start = end

        return chunks

    def chunk_section(
        self,
        section: LegalSection,
        source_url: str,
        base_id: str = ""
    ) -> List[Document]:
        """
        åˆ†å‰²ç« èŠ‚ä¸ºæ–‡æ¡£å—

        Args:
            section: æ³•å¾‹ç« èŠ‚
            source_url: æ¥æºURL
            base_id: åŸºç¡€ID

        Returns:
            æ–‡æ¡£å—åˆ—è¡¨
        """
        documents = []

        # ç”Ÿæˆå½“å‰ç« èŠ‚çš„ID
        section_id = f"{base_id}/{section.title}" if base_id else section.title

        # åˆ†å‰²å½“å‰ç« èŠ‚çš„å†…å®¹
        if section.content:
            chunks = self.chunk_text(section.content)

            for i, chunk in enumerate(chunks):
                doc = Document(
                    id=f"{section_id}#chunk{i}",
                    content=chunk,
                    source_url=source_url,
                    section_title=section.title,
                    metadata={
                        "level": section.level,
                        "chunk_index": i,
                        "total_chunks": len(chunks)
                    }
                )
                documents.append(doc)

        # é€’å½’å¤„ç†å­ç« èŠ‚
        for subsection in section.subsections:
            sub_documents = self.chunk_section(subsection, source_url, section_id)
            documents.extend(sub_documents)

        return documents

    def chunk_structured_content(
        self,
        content: StructuredContent
    ) -> List[Document]:
        """
        åˆ†å‰²ç»“æ„åŒ–å†…å®¹ä¸ºæ–‡æ¡£å—

        Args:
            content: ç»“æ„åŒ–å†…å®¹

        Returns:
            æ–‡æ¡£å—åˆ—è¡¨
        """
        documents = []

        # æ·»åŠ æ ‡é¢˜ä½œä¸ºç¬¬ä¸€ä¸ªæ–‡æ¡£
        if content.title:
            title_doc = Document(
                id=f"{content.url}#title",
                content=content.title,
                source_url=content.url,
                section_title="æ ‡é¢˜",
                metadata={
                    "level": 0,
                    "is_title": True,
                    "scraped_at": content.scraped_at.isoformat()
                }
            )
            documents.append(title_doc)

        # å¤„ç†æ‰€æœ‰ç« èŠ‚
        for section in content.sections:
            section_documents = self.chunk_section(section, content.url)
            documents.extend(section_documents)

        return documents

    def chunk_batch(
        self,
        contents: List[StructuredContent],
        show_progress: bool = True
    ) -> List[Document]:
        """
        æ‰¹é‡åˆ†å‰²æ–‡æ¡£

        Args:
            contents: ç»“æ„åŒ–å†…å®¹åˆ—è¡¨
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦

        Returns:
            æ‰€æœ‰æ–‡æ¡£å—
        """
        all_documents = []

        if show_progress:
            print(f"\nğŸ“ åˆ†å‰²æ–‡æ¡£: {len(contents)} ä¸ªæ–‡æ¡£")
            print("=" * 70)

        for i, content in enumerate(contents, 1):
            if show_progress:
                print(f"[{i}/{len(contents)}] {content.title}...", end=" ")

            documents = self.chunk_structured_content(content)
            all_documents.extend(documents)

            if show_progress:
                print(f"âœ… {len(documents)} å—")

        if show_progress:
            print("=" * 70)
            print(f"âœ… å®Œæˆ: æ€»å…± {len(all_documents)} ä¸ªæ–‡æ¡£å—")

        return all_documents


def main():
    """æµ‹è¯•å‡½æ•°"""
    print("ğŸ§ª æµ‹è¯•æ–‡æ¡£åˆ†å—å™¨")
    print("=" * 70)

    chunker = DocumentChunker(chunk_size=200, chunk_overlap=20)

    # æµ‹è¯•ç®€å•æ–‡æœ¬åˆ†å‰²
    print("\n[æµ‹è¯•1] ç®€å•æ–‡æœ¬åˆ†å‰²")
    print("-" * 70)

    text = """æ ¹æ®ã€Šä¸­åäººæ°‘å…±å’Œå›½åŠ³åŠ¨åˆåŒæ³•ã€‹ç¬¬46æ¡ã€ç¬¬47æ¡çš„è§„å®šï¼Œç”¨äººå•ä½åœ¨ä»¥ä¸‹æƒ…å½¢ä¸‹åº”å½“å‘åŠ³åŠ¨è€…æ”¯ä»˜ç»æµè¡¥å¿ã€‚
ç»æµè¡¥å¿æŒ‰åŠ³åŠ¨è€…åœ¨æœ¬å•ä½å·¥ä½œçš„å¹´é™ï¼Œæ¯æ»¡ä¸€å¹´æ”¯ä»˜ä¸€ä¸ªæœˆå·¥èµ„çš„æ ‡å‡†å‘åŠ³åŠ¨è€…æ”¯ä»˜ã€‚å…­ä¸ªæœˆä»¥ä¸Šä¸æ»¡ä¸€å¹´çš„ï¼ŒæŒ‰ä¸€å¹´è®¡ç®—ï¼›ä¸æ»¡å…­ä¸ªæœˆçš„ï¼Œå‘åŠ³åŠ¨è€…æ”¯ä»˜åŠä¸ªæœˆå·¥èµ„çš„ç»æµè¡¥å¿ã€‚
å¦‚æœç”¨äººå•ä½æœªæå‰30æ—¥ä»¥ä¹¦é¢å½¢å¼é€šçŸ¥åŠ³åŠ¨è€…è§£é™¤åŠ³åŠ¨åˆåŒï¼Œåº”é¢å¤–æ”¯ä»˜åŠ³åŠ¨è€…ä¸€ä¸ªæœˆå·¥èµ„ã€‚è¿™å°±æ˜¯å¸¸è¯´çš„"N+1"è¡¥å¿ã€‚"""

    print(f"åŸæ–‡ ({len(text)} å­—ç¬¦):")
    print(text[:100] + "...")

    chunks = chunker.chunk_text(text)
    print(f"\nåˆ†å‰²ç»“æœ: {len(chunks)} å—")
    for i, chunk in enumerate(chunks):
        print(f"\nå— {i+1} ({len(chunk)} å­—ç¬¦):")
        print(chunk)

    print("\n" + "=" * 70)
    print("âœ… æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    main()
