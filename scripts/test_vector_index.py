"""
æµ‹è¯•å‘é‡ç´¢å¼•å®Œæ•´æµç¨‹
ä»æ–‡æ¡£åˆ†å—åˆ°ç´¢å¼•æ„å»ºå†åˆ°çŸ¥è¯†æ£€ç´¢
"""
import sys
from pathlib import Path

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°è·¯å¾„
project_root = Path(__file__).parent.parent
sys.path.insert(0, str(project_root.parent))

from legal_rights.scraper import HTMLCleaner, ContentParser
from legal_rights.knowledge import (
    EmbeddingClient,
    DocumentChunker,
    VectorIndexer,
    KnowledgeRetriever
)
from legal_rights.config import Config


def test_embedding_client():
    """æµ‹è¯•Embeddingå®¢æˆ·ç«¯"""
    print("ğŸ§ª [æµ‹è¯•1] Embeddingå®¢æˆ·ç«¯")
    print("=" * 80)

    try:
        client = EmbeddingClient()
        print("âœ… å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
        print(f"   æ¨¡å‹: {client.model}")
        print(f"   ç»´åº¦: {client.get_embedding_dimension()}")

        # æµ‹è¯•å•ä¸ªæ–‡æœ¬
        text = "å…¬å¸æ¶æ„è¾é€€å‘˜å·¥åº”è¯¥å¦‚ä½•ç»´æƒï¼Ÿ"
        embedding = client.embed(text)
        print(f"\nâœ… æµ‹è¯•Embeddingç”ŸæˆæˆåŠŸ")
        print(f"   æ–‡æœ¬: {text}")
        print(f"   å‘é‡ç»´åº¦: {len(embedding)}")
        print(f"   å‘é‡å‰5ç»´: {embedding[:5]}")

        return True
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        return False


def test_document_chunker():
    """æµ‹è¯•æ–‡æ¡£åˆ†å—"""
    print("\n\nğŸ§ª [æµ‹è¯•2] æ–‡æ¡£åˆ†å—")
    print("=" * 80)

    # è¯»å–ç¤ºä¾‹HTML
    sample_html_path = project_root / "data" / "cache" / "sample_legal_content.html"
    if not sample_html_path.exists():
        print(f"âŒ ç¤ºä¾‹æ–‡ä»¶ä¸å­˜åœ¨: {sample_html_path}")
        return False

    html = sample_html_path.read_text(encoding='utf-8')

    # è§£æå†…å®¹
    cleaner = HTMLCleaner()
    parser = ContentParser()

    cleaned_html, _ = cleaner.clean_and_extract(html)
    structured = parser.parse(
        html=cleaned_html,
        url="https://example.com/sample",
        title="ç¦»èŒç»æµè¡¥å¿æŒ‡å—"
    )

    print(f"âœ… æ–‡æ¡£è§£æå®Œæˆ")
    print(f"   æ ‡é¢˜: {structured.title}")
    print(f"   ç« èŠ‚æ•°: {len(structured.sections)}")

    # åˆ†å—
    chunker = DocumentChunker(chunk_size=200, chunk_overlap=20)
    documents = chunker.chunk_structured_content(structured)

    print(f"\nâœ… æ–‡æ¡£åˆ†å—å®Œæˆ")
    print(f"   æ€»å—æ•°: {len(documents)}")
    print(f"\nå‰3ä¸ªæ–‡æ¡£å—:")
    for i, doc in enumerate(documents[:3], 1):
        print(f"\n  å— {i}:")
        print(f"    ID: {doc.id}")
        print(f"    ç« èŠ‚: {doc.section_title}")
        print(f"    é•¿åº¦: {len(doc.content)} å­—ç¬¦")
        print(f"    å†…å®¹é¢„è§ˆ: {doc.content[:100]}...")

    return structured, documents


def test_vector_indexer(structured):
    """æµ‹è¯•å‘é‡ç´¢å¼•æ„å»º"""
    print("\n\nğŸ§ª [æµ‹è¯•3] å‘é‡ç´¢å¼•æ„å»º")
    print("=" * 80)

    try:
        indexer = VectorIndexer()
        indexer.build_index([structured], show_progress=True)

        print(f"\nâœ… ç´¢å¼•æ„å»ºå®Œæˆ")
        stats = indexer.get_stats()
        print(f"   æ–‡æ¡£æ•°: {stats['total_documents']}")
        print(f"   å‘é‡ç»´åº¦: {stats['vector_dimension']}")

        # ä¿å­˜ç´¢å¼•
        indexer.save_index()

        return indexer
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return None


def test_knowledge_retriever():
    """æµ‹è¯•çŸ¥è¯†æ£€ç´¢"""
    print("\n\nğŸ§ª [æµ‹è¯•4] çŸ¥è¯†æ£€ç´¢")
    print("=" * 80)

    try:
        retriever = KnowledgeRetriever(auto_load=True)

        queries = [
            "å¦‚ä½•è®¡ç®—N+1ç»æµè¡¥å¿é‡‘ï¼Ÿ",
            "åŠ³åŠ¨ä»²è£éœ€è¦ä»€ä¹ˆææ–™ï¼Ÿ",
            "è¯•ç”¨æœŸè¢«è¾é€€æœ‰è¡¥å¿å—ï¼Ÿ"
        ]

        for query in queries:
            print(f"\næŸ¥è¯¢: {query}")
            print("-" * 70)

            results = retriever.retrieve(query, top_k=3)

            for i, (doc, score) in enumerate(results, 1):
                print(f"\n  ç»“æœ {i} (ç›¸ä¼¼åº¦: {score:.4f})")
                print(f"    ç« èŠ‚: {doc.section_title}")
                print(f"    å†…å®¹: {doc.content[:120]}...")

        print(f"\nâœ… æ£€ç´¢æµ‹è¯•å®Œæˆ")
        return True
    except Exception as e:
        print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return False


def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸš€ å‘é‡ç´¢å¼•æ¨¡å—å®Œæ•´æµ‹è¯•")
    print("=" * 80)
    print()

    # æ£€æŸ¥APIå¯†é’¥
    if not Config.OPENAI_API_KEY:
        print("âŒ é”™è¯¯: æœªé…ç½® OPENAI_API_KEY")
        print("   è¯·åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ : OPENAI_API_KEY=your-key")
        return

    results = {
        "embedding": False,
        "chunker": False,
        "indexer": False,
        "retriever": False
    }

    # æµ‹è¯•1: Embeddingå®¢æˆ·ç«¯
    results["embedding"] = test_embedding_client()

    if not results["embedding"]:
        print("\nâŒ Embeddingæµ‹è¯•å¤±è´¥ï¼Œç»ˆæ­¢æµ‹è¯•")
        return

    # æµ‹è¯•2: æ–‡æ¡£åˆ†å—
    test_result = test_document_chunker()
    if test_result:
        structured, documents = test_result
        results["chunker"] = True
    else:
        print("\nâŒ æ–‡æ¡£åˆ†å—æµ‹è¯•å¤±è´¥ï¼Œç»ˆæ­¢æµ‹è¯•")
        return

    # æµ‹è¯•3: å‘é‡ç´¢å¼•æ„å»º
    indexer = test_vector_indexer(structured)
    results["indexer"] = indexer is not None

    if not results["indexer"]:
        print("\nâŒ ç´¢å¼•æ„å»ºæµ‹è¯•å¤±è´¥ï¼Œç»ˆæ­¢æµ‹è¯•")
        return

    # æµ‹è¯•4: çŸ¥è¯†æ£€ç´¢
    results["retriever"] = test_knowledge_retriever()

    # æ€»ç»“
    print("\n\n" + "=" * 80)
    print("ğŸ“Š æµ‹è¯•æ€»ç»“")
    print("=" * 80)

    for test_name, success in results.items():
        status = "âœ… é€šè¿‡" if success else "âŒ å¤±è´¥"
        print(f"  {test_name:15s}: {status}")

    all_pass = all(results.values())
    print("\n" + "=" * 80)
    if all_pass:
        print("ğŸ‰ æ‰€æœ‰æµ‹è¯•é€šè¿‡ï¼")
    else:
        print("âš ï¸  éƒ¨åˆ†æµ‹è¯•å¤±è´¥")
    print("=" * 80)


if __name__ == "__main__":
    main()
