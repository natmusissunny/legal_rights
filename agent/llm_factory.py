"""
LLM å®¢æˆ·ç«¯å·¥å‚
æ ¹æ®é…ç½®è‡ªåŠ¨é€‰æ‹©åˆé€‚çš„ LLM å®¢æˆ·ç«¯
æ”¯æŒ: Claude, é€šä¹‰åƒé—®, DeepSeek, æ™ºè°±AI(GLM), å…ƒå®(MiniMax), Kimi
"""
from typing import Optional, List, Dict
from ..config import Config


class LLMClientBase:
    """LLMå®¢æˆ·ç«¯åŸºç±»"""

    def complete(
        self,
        prompt: str,
        system: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: Optional[int] = None
    ) -> str:
        """ç”Ÿæˆå•æ¬¡å›å¤"""
        raise NotImplementedError

    def chat(
        self,
        messages: List[Dict[str, str]],
        system: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: Optional[int] = None
    ) -> str:
        """å¤šè½®å¯¹è¯"""
        raise NotImplementedError


class ClaudeClient(LLMClientBase):
    """Claude API å®¢æˆ·ç«¯"""

    def __init__(self, api_key: Optional[str] = None):
        from anthropic import Anthropic
        self.api_key = api_key or Config.CLAUDE_API_KEY
        if not self.api_key:
            raise ValueError("Claude API key is required")

        self.client = Anthropic(api_key=self.api_key)
        self.model = Config.CLAUDE_MODEL
        self.max_tokens = Config.MAX_TOKENS

    def complete(
        self,
        prompt: str,
        system: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: Optional[int] = None
    ) -> str:
        max_tokens = max_tokens or self.max_tokens

        response = self.client.messages.create(
            model=self.model,
            max_tokens=max_tokens,
            temperature=temperature,
            system=system or "",
            messages=[{"role": "user", "content": prompt}]
        )

        return response.content[0].text

    def chat(
        self,
        messages: List[Dict[str, str]],
        system: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: Optional[int] = None
    ) -> str:
        max_tokens = max_tokens or self.max_tokens

        response = self.client.messages.create(
            model=self.model,
            max_tokens=max_tokens,
            temperature=temperature,
            system=system or "",
            messages=messages
        )

        return response.content[0].text


class QwenClient(LLMClientBase):
    """é€šä¹‰åƒé—® API å®¢æˆ·ç«¯"""

    def __init__(self, api_key: Optional[str] = None):
        try:
            from dashscope import Generation
        except ImportError:
            raise ImportError("è¯·å…ˆå®‰è£…é€šä¹‰åƒé—®SDK: pip install dashscope")

        self.api_key = api_key or Config.DASHSCOPE_API_KEY
        if not self.api_key:
            raise ValueError("Dashscope API key is required")

        self.Generation = Generation
        self.model = Config.QWEN_MODEL
        self.max_tokens = Config.MAX_TOKENS

        # è®¾ç½®APIå¯†é’¥
        import dashscope
        dashscope.api_key = self.api_key

    def complete(
        self,
        prompt: str,
        system: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: Optional[int] = None
    ) -> str:
        max_tokens = max_tokens or self.max_tokens

        messages = []
        if system:
            messages.append({"role": "system", "content": system})
        messages.append({"role": "user", "content": prompt})

        response = self.Generation.call(
            model=self.model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
            result_format='message'
        )

        if response.status_code == 200:
            return response.output.choices[0].message.content
        else:
            raise Exception(f"é€šä¹‰åƒé—®APIè°ƒç”¨å¤±è´¥: {response.message}")

    def chat(
        self,
        messages: List[Dict[str, str]],
        system: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: Optional[int] = None
    ) -> str:
        max_tokens = max_tokens or self.max_tokens

        # å¦‚æœæœ‰systemï¼Œæ’å…¥åˆ°å¼€å¤´
        if system:
            messages = [{"role": "system", "content": system}] + messages

        response = self.Generation.call(
            model=self.model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens,
            result_format='message'
        )

        if response.status_code == 200:
            return response.output.choices[0].message.content
        else:
            raise Exception(f"é€šä¹‰åƒé—®APIè°ƒç”¨å¤±è´¥: {response.message}")


class DeepSeekClient(LLMClientBase):
    """DeepSeek API å®¢æˆ·ç«¯ï¼ˆå…¼å®¹OpenAIæ¥å£ï¼‰"""

    def __init__(self, api_key: Optional[str] = None):
        try:
            from openai import OpenAI
        except ImportError:
            raise ImportError("è¯·å…ˆå®‰è£…OpenAI SDK: pip install openai")

        self.api_key = api_key or Config.DEEPSEEK_API_KEY
        if not self.api_key:
            raise ValueError("DeepSeek API key is required")

        self.client = OpenAI(
            api_key=self.api_key,
            base_url="https://api.deepseek.com"
        )
        self.model = Config.DEEPSEEK_MODEL
        self.max_tokens = Config.MAX_TOKENS

    def complete(
        self,
        prompt: str,
        system: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: Optional[int] = None
    ) -> str:
        max_tokens = max_tokens or self.max_tokens

        messages = []
        if system:
            messages.append({"role": "system", "content": system})
        messages.append({"role": "user", "content": prompt})

        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens
        )

        return response.choices[0].message.content

    def chat(
        self,
        messages: List[Dict[str, str]],
        system: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: Optional[int] = None
    ) -> str:
        max_tokens = max_tokens or self.max_tokens

        if system:
            messages = [{"role": "system", "content": system}] + messages

        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens
        )

        return response.choices[0].message.content


class ZhipuClient(LLMClientBase):
    """æ™ºè°±AI (GLM) API å®¢æˆ·ç«¯"""

    def __init__(self, api_key: Optional[str] = None):
        try:
            from zhipuai import ZhipuAI
        except ImportError:
            raise ImportError("è¯·å…ˆå®‰è£…æ™ºè°±AI SDK: pip install zhipuai")

        self.api_key = api_key or Config.ZHIPUAI_API_KEY
        if not self.api_key:
            raise ValueError("Zhipu AI API key is required")

        self.client = ZhipuAI(api_key=self.api_key)
        self.model = Config.ZHIPU_CHAT_MODEL
        self.max_tokens = Config.MAX_TOKENS

    def complete(
        self,
        prompt: str,
        system: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: Optional[int] = None
    ) -> str:
        max_tokens = max_tokens or self.max_tokens

        messages = []
        if system:
            messages.append({"role": "system", "content": system})
        messages.append({"role": "user", "content": prompt})

        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens
        )

        return response.choices[0].message.content

    def chat(
        self,
        messages: List[Dict[str, str]],
        system: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: Optional[int] = None
    ) -> str:
        max_tokens = max_tokens or self.max_tokens

        if system:
            messages = [{"role": "system", "content": system}] + messages

        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens
        )

        return response.choices[0].message.content


class MinimaxClient(LLMClientBase):
    """å…ƒå® (MiniMax) API å®¢æˆ·ç«¯"""

    def __init__(self, api_key: Optional[str] = None, group_id: Optional[str] = None):
        try:
            import requests
        except ImportError:
            raise ImportError("è¯·å…ˆå®‰è£… requests: pip install requests")

        self.api_key = api_key or Config.MINIMAX_API_KEY
        self.group_id = group_id or Config.MINIMAX_GROUP_ID
        if not self.api_key or not self.group_id:
            raise ValueError("MiniMax API key and group_id are required")

        self.requests = requests
        self.model = Config.MINIMAX_MODEL
        self.max_tokens = Config.MAX_TOKENS
        self.base_url = f"https://api.minimax.chat/v1/text/chatcompletion_v2?GroupId={self.group_id}"

    def complete(
        self,
        prompt: str,
        system: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: Optional[int] = None
    ) -> str:
        max_tokens = max_tokens or self.max_tokens

        messages = []
        if system:
            messages.append({"role": "system", "content": system})
        messages.append({"role": "user", "content": prompt})

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        data = {
            "model": self.model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens
        }

        response = self.requests.post(self.base_url, headers=headers, json=data)
        response.raise_for_status()

        result = response.json()
        return result["choices"][0]["message"]["content"]

    def chat(
        self,
        messages: List[Dict[str, str]],
        system: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: Optional[int] = None
    ) -> str:
        max_tokens = max_tokens or self.max_tokens

        if system:
            messages = [{"role": "system", "content": system}] + messages

        headers = {
            "Authorization": f"Bearer {self.api_key}",
            "Content-Type": "application/json"
        }

        data = {
            "model": self.model,
            "messages": messages,
            "temperature": temperature,
            "max_tokens": max_tokens
        }

        response = self.requests.post(self.base_url, headers=headers, json=data)
        response.raise_for_status()

        result = response.json()
        return result["choices"][0]["message"]["content"]


class KimiClient(LLMClientBase):
    """Kimi (æœˆä¹‹æš—é¢) API å®¢æˆ·ç«¯ï¼ˆå…¼å®¹OpenAIæ¥å£ï¼‰"""

    def __init__(self, api_key: Optional[str] = None):
        try:
            from openai import OpenAI
        except ImportError:
            raise ImportError("è¯·å…ˆå®‰è£…OpenAI SDK: pip install openai")

        self.api_key = api_key or Config.KIMI_API_KEY
        if not self.api_key:
            raise ValueError("Kimi API key is required")

        self.client = OpenAI(
            api_key=self.api_key,
            base_url="https://api.moonshot.cn/v1"
        )
        self.model = Config.KIMI_MODEL
        self.max_tokens = Config.MAX_TOKENS

    def complete(
        self,
        prompt: str,
        system: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: Optional[int] = None
    ) -> str:
        max_tokens = max_tokens or self.max_tokens

        messages = []
        if system:
            messages.append({"role": "system", "content": system})
        messages.append({"role": "user", "content": prompt})

        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens
        )

        return response.choices[0].message.content

    def chat(
        self,
        messages: List[Dict[str, str]],
        system: Optional[str] = None,
        temperature: float = 0.7,
        max_tokens: Optional[int] = None
    ) -> str:
        max_tokens = max_tokens or self.max_tokens

        if system:
            messages = [{"role": "system", "content": system}] + messages

        response = self.client.chat.completions.create(
            model=self.model,
            messages=messages,
            temperature=temperature,
            max_tokens=max_tokens
        )

        return response.choices[0].message.content


def create_llm_client(llm_type: Optional[str] = None) -> LLMClientBase:
    """
    åˆ›å»ºLLMå®¢æˆ·ç«¯

    Args:
        llm_type: æŒ‡å®šç±»å‹ ('claude', 'qwen', 'deepseek', 'zhipu', 'minimax', 'kimi') æˆ– Noneï¼ˆè‡ªåŠ¨é€‰æ‹©ï¼‰

    Returns:
        LLMå®¢æˆ·ç«¯å®ä¾‹

    Raises:
        ValueError: å¦‚æœæ²¡æœ‰å¯ç”¨çš„é…ç½®
    """
    # å¦‚æœæŒ‡å®šäº†ç±»å‹
    if llm_type:
        client_map = {
            "claude": ClaudeClient,
            "qwen": QwenClient,
            "deepseek": DeepSeekClient,
            "zhipu": ZhipuClient,
            "minimax": MinimaxClient,
            "kimi": KimiClient,
        }

        if llm_type not in client_map:
            raise ValueError(f"æœªçŸ¥çš„LLMç±»å‹: {llm_type}")

        print(f"ğŸ“¦ ä½¿ç”¨ {llm_type.upper()} LLM")
        return client_map[llm_type]()

    # è‡ªåŠ¨é€‰æ‹©
    selected = Config.auto_select_llm()

    if not selected:
        raise ValueError(
            "æœªé…ç½®ä»»ä½•LLM APIå¯†é’¥\n"
            "è¯·åœ¨ .env æ–‡ä»¶ä¸­é…ç½®ä»¥ä¸‹ä»»ä¸€é¡¹:\n"
            "  DASHSCOPE_API_KEY=your-key     # é€šä¹‰åƒé—®ï¼ˆæ¨èï¼Œå›½å†…ï¼‰\n"
            "  DEEPSEEK_API_KEY=your-key      # DeepSeekï¼ˆæ¨èï¼Œä¾¿å®œï¼‰\n"
            "  ZHIPUAI_API_KEY=your-key       # æ™ºè°±AI GLMï¼ˆå›½å†…ï¼‰\n"
            "  KIMI_API_KEY=your-key          # Kimi æœˆä¹‹æš—é¢ï¼ˆå›½å†…ï¼‰\n"
            "  MINIMAX_API_KEY=your-key       # å…ƒå® MiniMaxï¼ˆå›½å†…ï¼‰\n"
            "  CLAUDE_API_KEY=your-key        # Claudeï¼ˆå›½é™…ï¼Œéœ€ä»£ç†ï¼‰"
        )

    client_map = {
        "qwen": (QwenClient, "é€šä¹‰åƒé—® Qwen"),
        "deepseek": (DeepSeekClient, "DeepSeek"),
        "zhipu": (ZhipuClient, "æ™ºè°±AI GLM"),
        "kimi": (KimiClient, "Kimi æœˆä¹‹æš—é¢"),
        "minimax": (MinimaxClient, "å…ƒå® MiniMax"),
        "claude": (ClaudeClient, "Claude"),
    }

    if selected in client_map:
        client_class, display_name = client_map[selected]
        print(f"ğŸ“¦ ä½¿ç”¨ {display_name} (è‡ªåŠ¨é€‰æ‹©)")
        return client_class()
    else:
        raise ValueError(f"æœªçŸ¥çš„LLMé€‰æ‹©: {selected}")
