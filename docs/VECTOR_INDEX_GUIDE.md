# å‘é‡ç´¢å¼•ä½¿ç”¨æŒ‡å—

æœ¬æ–‡æ¡£è¯´æ˜å¦‚ä½•æ„å»ºå’Œä½¿ç”¨å‘é‡ç´¢å¼•è¿›è¡Œè¯­ä¹‰æ£€ç´¢ã€‚

## ğŸ“‹ å‰ç½®è¦æ±‚

### 1. API å¯†é’¥

å‘é‡ç´¢å¼•éœ€è¦ OpenAI API å¯†é’¥ç”¨äºç”Ÿæˆæ–‡æœ¬å‘é‡ï¼ˆEmbeddingï¼‰ã€‚

**è·å– API å¯†é’¥**:
1. è®¿é—® [OpenAI Platform](https://platform.openai.com/)
2. æ³¨å†Œ/ç™»å½•è´¦å·
3. è¿›å…¥ API Keys é¡µé¢
4. åˆ›å»ºæ–°çš„ Secret Key
5. å¤åˆ¶å¹¶ä¿å­˜å¯†é’¥

**é…ç½®å¯†é’¥**:

åœ¨é¡¹ç›®æ ¹ç›®å½•çš„ `.env` æ–‡ä»¶ä¸­æ·»åŠ ï¼š

```env
OPENAI_API_KEY=sk-your-actual-key-here
```

### 2. å®‰è£…ä¾èµ–

```bash
pip install openai faiss-cpu numpy
```

## ğŸ—ï¸ æ„å»ºç´¢å¼•

### å®Œæ•´æµç¨‹

```python
from legal_rights.scraper import HTMLCleaner, ContentParser
from legal_rights.knowledge import VectorIndexer

# 1. è§£æHTMLå†…å®¹
cleaner = HTMLCleaner()
parser = ContentParser()

html = open("sample.html").read()
cleaned_html, _ = cleaner.clean_and_extract(html)
structured = parser.parse(cleaned_html, url="https://example.com", title="æ ‡é¢˜")

# 2. æ„å»ºå‘é‡ç´¢å¼•
indexer = VectorIndexer()
indexer.build_index([structured], show_progress=True)

# 3. ä¿å­˜ç´¢å¼•
indexer.save_index()
```

### ä½¿ç”¨æµ‹è¯•è„šæœ¬

```bash
python -m legal_rights.scripts.test_vector_index
```

è¿™å°†æ‰§è¡Œå®Œæ•´çš„æµ‹è¯•æµç¨‹ï¼š
1. æµ‹è¯• Embedding å®¢æˆ·ç«¯
2. æµ‹è¯•æ–‡æ¡£åˆ†å—
3. æ„å»ºå‘é‡ç´¢å¼•
4. æµ‹è¯•çŸ¥è¯†æ£€ç´¢

## ğŸ” æ£€ç´¢æ–‡æ¡£

### åŸºç¡€æ£€ç´¢

```python
from legal_rights.knowledge import KnowledgeRetriever

# åˆå§‹åŒ–æ£€ç´¢å™¨ï¼ˆè‡ªåŠ¨åŠ è½½ç´¢å¼•ï¼‰
retriever = KnowledgeRetriever(auto_load=True)

# æ£€ç´¢ç›¸å…³æ–‡æ¡£
query = "å¦‚ä½•è®¡ç®—N+1ç»æµè¡¥å¿é‡‘ï¼Ÿ"
results = retriever.retrieve(query, top_k=5)

for doc, score in results:
    print(f"ç›¸ä¼¼åº¦: {score:.4f}")
    print(f"ç« èŠ‚: {doc.section_title}")
    print(f"å†…å®¹: {doc.content}")
```

### é«˜çº§æ£€ç´¢

#### 1. è®¾ç½®ç›¸ä¼¼åº¦é˜ˆå€¼

```python
# åªè¿”å›ç›¸ä¼¼åº¦ > 0.5 çš„ç»“æœ
results = retriever.retrieve(
    query="ç»æµè¡¥å¿",
    top_k=10,
    min_score=0.5
)
```

#### 2. è¿‡æ»¤ç‰¹å®šç« èŠ‚

```python
# åªæ£€ç´¢ç‰¹å®šç« èŠ‚
results = retriever.retrieve(
    query="è¡¥å¿æ ‡å‡†",
    filter_section="ç»æµè¡¥å¿çš„è®¡ç®—æ–¹æ³•"
)
```

#### 3. è·å–ä¸Šä¸‹æ–‡æ–‡æœ¬

```python
# ç›´æ¥è·å–ç»„åˆå¥½çš„ä¸Šä¸‹æ–‡
context = retriever.retrieve_with_context(
    query="ç»´æƒæµç¨‹",
    top_k=3
)
print(context)
```

#### 4. å…³é”®è¯æ£€ç´¢

```python
# åŸºäºå…³é”®è¯åŒ¹é…
keywords = ["N+1", "è¡¥å¿é‡‘", "ä»£é€šçŸ¥é‡‘"]
results = retriever.retrieve_by_keyword(keywords, top_k=5)
```

#### 5. æ··åˆæ£€ç´¢

```python
# ç»“åˆå‘é‡ç›¸ä¼¼åº¦å’Œå…³é”®è¯åŒ¹é…
results = retriever.hybrid_retrieve(
    query="ç»æµè¡¥å¿è®¡ç®—",
    keywords=["è¡¥å¿", "å·¥èµ„", "å¹´é™"],
    top_k=5,
    vector_weight=0.7  # å‘é‡æƒé‡70%ï¼Œå…³é”®è¯æƒé‡30%
)
```

## ğŸ“Š ç´¢å¼•ç»Ÿè®¡

### æŸ¥çœ‹ç´¢å¼•ä¿¡æ¯

```python
retriever = KnowledgeRetriever(auto_load=True)
stats = retriever.get_stats()

print(f"å·²ç´¢å¼•: {stats['indexed']}")
print(f"æ–‡æ¡£æ•°: {stats['total_documents']}")
print(f"å‘é‡ç»´åº¦: {stats['vector_dimension']}")
print(f"æ¥æº: {stats['sources']}")
print(f"ç« èŠ‚: {stats['sections']}")
```

### æŸ¥çœ‹ç»Ÿè®¡æ–‡ä»¶

ç´¢å¼•æ„å»ºåä¼šç”Ÿæˆç»Ÿè®¡æ–‡ä»¶ï¼š

```bash
cat data/vectors/stats.json
```

è¾“å‡ºç¤ºä¾‹ï¼š

```json
{
  "total_documents": 45,
  "vector_dimension": 1536,
  "index_type": "IndexFlatL2",
  "sources": [
    "https://example.com/sample"
  ],
  "sections": [
    "æ ‡é¢˜",
    "ä¸€ã€ç»æµè¡¥å¿çš„æ³•å¾‹ä¾æ®",
    "1.1 åº”æ”¯ä»˜ç»æµè¡¥å¿çš„æƒ…å½¢",
    ...
  ]
}
```

## âš™ï¸ é…ç½®å‚æ•°

### åˆ†å—å‚æ•°

åœ¨ `config.py` æˆ– `.env` ä¸­é…ç½®ï¼š

```python
CHUNK_SIZE = 512      # åˆ†å—å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰
CHUNK_OVERLAP = 50    # é‡å å¤§å°ï¼ˆå­—ç¬¦æ•°ï¼‰
```

è¾ƒå¤§çš„ `CHUNK_SIZE` æä¾›æ›´å¤šä¸Šä¸‹æ–‡ï¼Œä½†å¯èƒ½é™ä½æ£€ç´¢ç²¾åº¦ã€‚
è¾ƒå¤§çš„ `CHUNK_OVERLAP` æé«˜è¿ç»­æ€§ï¼Œä½†å¢åŠ å­˜å‚¨å¼€é”€ã€‚

### æ£€ç´¢å‚æ•°

```python
TOP_K_RESULTS = 5     # é»˜è®¤è¿”å›çš„ç»“æœæ•°é‡
```

### Embedding æ¨¡å‹

é»˜è®¤ä½¿ç”¨ `text-embedding-3-small`ï¼ˆ1536ç»´ï¼‰ã€‚

å¦‚éœ€æ›´é«˜ç²¾åº¦ï¼Œå¯åœ¨ `config.py` ä¸­ä¿®æ”¹ï¼š

```python
EMBEDDING_MODEL = "text-embedding-3-large"  # 3072ç»´ï¼Œæˆæœ¬æ›´é«˜
```

## ğŸ’° æˆæœ¬ä¼°ç®—

### OpenAI Embedding API å®šä»·

| æ¨¡å‹ | ä»·æ ¼ | ç»´åº¦ |
|------|------|------|
| text-embedding-3-small | $0.02 / 1M tokens | 1536 |
| text-embedding-3-large | $0.13 / 1M tokens | 3072 |

### ç¤ºä¾‹æˆæœ¬

å‡è®¾çŸ¥è¯†åº“æœ‰ **50,000 å­—ç¬¦**ï¼ˆçº¦ 12,500 tokensï¼‰ï¼š

- **æ„å»ºç´¢å¼•**: $0.02 Ã— (12,500 / 1,000,000) = **$0.00025**
- **å•æ¬¡æŸ¥è¯¢**: $0.02 Ã— (50 / 1,000,000) = **$0.000001**

**ç»“è®º**: æˆæœ¬æä½ï¼Œå¯å¿½ç•¥ä¸è®¡ã€‚

## ğŸ“ æ–‡ä»¶ç»“æ„

ç´¢å¼•æ„å»ºåä¼šç”Ÿæˆä»¥ä¸‹æ–‡ä»¶ï¼š

```
data/vectors/
â”œâ”€â”€ index.faiss        # FAISS å‘é‡ç´¢å¼•ï¼ˆäºŒè¿›åˆ¶ï¼‰
â”œâ”€â”€ metadata.pkl       # æ–‡æ¡£å…ƒæ•°æ®ï¼ˆPython pickleï¼‰
â””â”€â”€ stats.json         # ç»Ÿè®¡ä¿¡æ¯ï¼ˆJSONï¼‰
```

## ğŸ”§ æ•…éšœæ’é™¤

### é—®é¢˜1: "Index not found"

**åŸå› **: ç´¢å¼•æ–‡ä»¶ä¸å­˜åœ¨

**è§£å†³**:
```bash
python scripts/test_vector_index.py
```

### é—®é¢˜2: "OpenAI API key is required"

**åŸå› **: API å¯†é’¥æœªé…ç½®

**è§£å†³**:
1. æ£€æŸ¥ `.env` æ–‡ä»¶æ˜¯å¦å­˜åœ¨
2. ç¡®è®¤ `OPENAI_API_KEY` æ­£ç¡®é…ç½®
3. é‡å¯ Python è¿›ç¨‹

### é—®é¢˜3: Rate limit exceeded

**åŸå› **: è¯·æ±‚é¢‘ç‡è¿‡é«˜

**è§£å†³**:

åœ¨ `.env` ä¸­é™ä½é€Ÿç‡é™åˆ¶ï¼š

```env
RATE_LIMIT_PER_SECOND=2
```

### é—®é¢˜4: æ£€ç´¢ç»“æœä¸ç›¸å…³

**å¯èƒ½åŸå› **:
1. æŸ¥è¯¢è¡¨è¾¾ä¸å¤Ÿå‡†ç¡®
2. åˆ†å—å‚æ•°ä¸åˆé€‚
3. çŸ¥è¯†åº“å†…å®¹ä¸è¶³

**è§£å†³**:
1. å°è¯•ä¸åŒçš„æŸ¥è¯¢æ–¹å¼
2. è°ƒæ•´ `CHUNK_SIZE` å’Œ `CHUNK_OVERLAP`
3. ä½¿ç”¨æ··åˆæ£€ç´¢ï¼ˆç»“åˆå…³é”®è¯ï¼‰
4. æ‰©å……çŸ¥è¯†åº“å†…å®¹

## ğŸš€ æœ€ä½³å®è·µ

### 1. å®šæœŸæ›´æ–°ç´¢å¼•

æ³•å¾‹æ³•è§„å¯èƒ½æ›´æ–°ï¼Œå»ºè®®å®šæœŸé‡å»ºç´¢å¼•ï¼š

```bash
# åˆ é™¤æ—§ç´¢å¼•
rm -rf data/vectors/*

# é‡æ–°æ„å»º
python scripts/test_vector_index.py
```

### 2. è°ƒä¼˜æ£€ç´¢å‚æ•°

æ ¹æ®å®é™…æ•ˆæœè°ƒæ•´ï¼š

- **top_k**: è¿”å›æ›´å¤šç»“æœæé«˜å¬å›ç‡ï¼Œä½†å¯èƒ½å¼•å…¥å™ªå£°
- **min_score**: è®¾ç½®é˜ˆå€¼è¿‡æ»¤ä½ç›¸å…³æ€§ç»“æœ
- **vector_weight**: å¹³è¡¡å‘é‡å’Œå…³é”®è¯çš„æƒé‡

### 3. ç›‘æ§æˆæœ¬

è™½ç„¶æˆæœ¬å¾ˆä½ï¼Œä½†ä»å»ºè®®ç›‘æ§ OpenAI API ä½¿ç”¨ï¼š

```bash
# æŸ¥çœ‹ API ä½¿ç”¨æƒ…å†µ
# https://platform.openai.com/usage
```

### 4. å¤‡ä»½ç´¢å¼•

ç´¢å¼•æ–‡ä»¶å¾ˆå°ï¼Œå»ºè®®å¤‡ä»½ï¼š

```bash
tar -czf vectors_backup_$(date +%Y%m%d).tar.gz data/vectors/
```

## ğŸ“š å‚è€ƒèµ„æ–™

- [OpenAI Embeddings Guide](https://platform.openai.com/docs/guides/embeddings)
- [FAISS Documentation](https://github.com/facebookresearch/faiss/wiki)
- [å‘é‡æ£€ç´¢æœ€ä½³å®è·µ](https://www.pinecone.io/learn/vector-search/)

---

**ç‰ˆæœ¬**: 1.0
**æ›´æ–°æ—¥æœŸ**: 2026-02-06
