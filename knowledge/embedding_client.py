"""
Embedding API å®¢æˆ·ç«¯
ä½¿ç”¨ OpenAI Embedding API ç”Ÿæˆæ–‡æœ¬å‘é‡
"""
import asyncio
import time
from typing import List, Optional
from openai import OpenAI
import numpy as np

from ..config import Config


class EmbeddingClient:
    """Embedding API å®¢æˆ·ç«¯"""

    def __init__(self, api_key: Optional[str] = None):
        """
        åˆå§‹åŒ–å®¢æˆ·ç«¯

        Args:
            api_key: OpenAI APIå¯†é’¥ï¼ˆå¦‚æœä¸ºNoneåˆ™ä»Configè¯»å–ï¼‰
        """
        self.api_key = api_key or Config.OPENAI_API_KEY
        if not self.api_key:
            raise ValueError("OpenAI API key is required")

        self.client = OpenAI(api_key=self.api_key)
        self.model = Config.EMBEDDING_MODEL
        self.rate_limit = Config.RATE_LIMIT_PER_SECOND
        self._last_request_time = 0

    async def _wait_for_rate_limit(self):
        """ç­‰å¾…é€Ÿç‡é™åˆ¶"""
        current_time = time.time()
        time_since_last = current_time - self._last_request_time
        min_interval = 1.0 / self.rate_limit

        if time_since_last < min_interval:
            await asyncio.sleep(min_interval - time_since_last)

        self._last_request_time = time.time()

    def embed(self, text: str) -> List[float]:
        """
        ç”Ÿæˆå•ä¸ªæ–‡æœ¬çš„å‘é‡

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            å‘é‡ï¼ˆæµ®ç‚¹æ•°åˆ—è¡¨ï¼‰
        """
        if not text or not text.strip():
            raise ValueError("Text cannot be empty")

        try:
            response = self.client.embeddings.create(
                model=self.model,
                input=text
            )
            return response.data[0].embedding
        except Exception as e:
            print(f"âŒ Embeddingç”Ÿæˆå¤±è´¥: {e}")
            raise

    async def embed_async(self, text: str) -> List[float]:
        """
        å¼‚æ­¥ç”Ÿæˆå•ä¸ªæ–‡æœ¬çš„å‘é‡

        Args:
            text: è¾“å…¥æ–‡æœ¬

        Returns:
            å‘é‡ï¼ˆæµ®ç‚¹æ•°åˆ—è¡¨ï¼‰
        """
        await self._wait_for_rate_limit()
        return self.embed(text)

    def embed_batch(
        self,
        texts: List[str],
        batch_size: int = 100,
        show_progress: bool = True
    ) -> List[List[float]]:
        """
        æ‰¹é‡ç”Ÿæˆæ–‡æœ¬å‘é‡

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            batch_size: æ‰¹æ¬¡å¤§å°ï¼ˆOpenAI APIæœ€å¤§2048ï¼‰
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦

        Returns:
            å‘é‡åˆ—è¡¨
        """
        if not texts:
            return []

        all_embeddings = []
        total_batches = (len(texts) + batch_size - 1) // batch_size

        if show_progress:
            print(f"\nğŸ”„ æ‰¹é‡ç”ŸæˆEmbedding: {len(texts)} ä¸ªæ–‡æœ¬ï¼Œ{total_batches} ä¸ªæ‰¹æ¬¡")
            print("=" * 70)

        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i + batch_size]
            batch_num = i // batch_size + 1

            try:
                if show_progress:
                    print(f"[æ‰¹æ¬¡ {batch_num}/{total_batches}] å¤„ç† {len(batch_texts)} ä¸ªæ–‡æœ¬...", end=" ")

                response = self.client.embeddings.create(
                    model=self.model,
                    input=batch_texts
                )

                batch_embeddings = [item.embedding for item in response.data]
                all_embeddings.extend(batch_embeddings)

                if show_progress:
                    print(f"âœ… å®Œæˆ")

                # é€Ÿç‡é™åˆ¶
                if i + batch_size < len(texts):
                    time.sleep(1.0 / self.rate_limit)

            except Exception as e:
                print(f"âŒ æ‰¹æ¬¡ {batch_num} å¤±è´¥: {e}")
                # å¤±è´¥æ—¶æ·»åŠ é›¶å‘é‡
                embedding_dim = 1536  # text-embedding-3-small çš„ç»´åº¦
                all_embeddings.extend([[0.0] * embedding_dim] * len(batch_texts))

        if show_progress:
            success_count = sum(1 for emb in all_embeddings if emb != [0.0] * len(emb))
            print("=" * 70)
            print(f"âœ… å®Œæˆ: {success_count}/{len(texts)} æˆåŠŸ")

        return all_embeddings

    async def embed_batch_async(
        self,
        texts: List[str],
        batch_size: int = 100,
        show_progress: bool = True
    ) -> List[List[float]]:
        """
        å¼‚æ­¥æ‰¹é‡ç”Ÿæˆæ–‡æœ¬å‘é‡

        Args:
            texts: æ–‡æœ¬åˆ—è¡¨
            batch_size: æ‰¹æ¬¡å¤§å°
            show_progress: æ˜¯å¦æ˜¾ç¤ºè¿›åº¦

        Returns:
            å‘é‡åˆ—è¡¨
        """
        if not texts:
            return []

        all_embeddings = []
        total_batches = (len(texts) + batch_size - 1) // batch_size

        if show_progress:
            print(f"\nğŸ”„ å¼‚æ­¥æ‰¹é‡ç”ŸæˆEmbedding: {len(texts)} ä¸ªæ–‡æœ¬ï¼Œ{total_batches} ä¸ªæ‰¹æ¬¡")
            print("=" * 70)

        for i in range(0, len(texts), batch_size):
            batch_texts = texts[i:i + batch_size]
            batch_num = i // batch_size + 1

            await self._wait_for_rate_limit()

            try:
                if show_progress:
                    print(f"[æ‰¹æ¬¡ {batch_num}/{total_batches}] å¤„ç† {len(batch_texts)} ä¸ªæ–‡æœ¬...", end=" ")

                response = self.client.embeddings.create(
                    model=self.model,
                    input=batch_texts
                )

                batch_embeddings = [item.embedding for item in response.data]
                all_embeddings.extend(batch_embeddings)

                if show_progress:
                    print(f"âœ… å®Œæˆ")

            except Exception as e:
                print(f"âŒ æ‰¹æ¬¡ {batch_num} å¤±è´¥: {e}")
                embedding_dim = 1536
                all_embeddings.extend([[0.0] * embedding_dim] * len(batch_texts))

        if show_progress:
            success_count = sum(1 for emb in all_embeddings if emb != [0.0] * len(emb))
            print("=" * 70)
            print(f"âœ… å®Œæˆ: {success_count}/{len(texts)} æˆåŠŸ")

        return all_embeddings

    def get_embedding_dimension(self) -> int:
        """
        è·å–Embeddingç»´åº¦

        Returns:
            å‘é‡ç»´åº¦
        """
        # text-embedding-3-small: 1536ç»´
        # text-embedding-3-large: 3072ç»´
        if "large" in self.model:
            return 3072
        else:
            return 1536

    def cosine_similarity(self, vec1: List[float], vec2: List[float]) -> float:
        """
        è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦

        Args:
            vec1: å‘é‡1
            vec2: å‘é‡2

        Returns:
            ç›¸ä¼¼åº¦ï¼ˆ0-1ï¼‰
        """
        v1 = np.array(vec1)
        v2 = np.array(vec2)

        # è®¡ç®—ä½™å¼¦ç›¸ä¼¼åº¦
        dot_product = np.dot(v1, v2)
        norm1 = np.linalg.norm(v1)
        norm2 = np.linalg.norm(v2)

        if norm1 == 0 or norm2 == 0:
            return 0.0

        return float(dot_product / (norm1 * norm2))


def main():
    """æµ‹è¯•å‡½æ•°"""
    import os

    # æ£€æŸ¥APIå¯†é’¥
    if not Config.OPENAI_API_KEY:
        print("âŒ è¯·å…ˆé…ç½® OPENAI_API_KEY")
        print("   åœ¨ .env æ–‡ä»¶ä¸­æ·»åŠ : OPENAI_API_KEY=your-key")
        return

    print("ğŸ§ª æµ‹è¯• Embedding å®¢æˆ·ç«¯")
    print("=" * 70)

    client = EmbeddingClient()

    # æµ‹è¯•å•ä¸ªæ–‡æœ¬
    print("\n[æµ‹è¯•1] å•ä¸ªæ–‡æœ¬Embedding")
    print("-" * 70)
    text = "å…¬å¸æ¶æ„è¾é€€å‘˜å·¥åº”è¯¥å¦‚ä½•ç»´æƒï¼Ÿ"
    print(f"æ–‡æœ¬: {text}")

    try:
        embedding = client.embed(text)
        print(f"âœ… Embeddingç”ŸæˆæˆåŠŸ")
        print(f"   ç»´åº¦: {len(embedding)}")
        print(f"   å‰10ç»´: {embedding[:10]}")
    except Exception as e:
        print(f"âŒ å¤±è´¥: {e}")
        return

    # æµ‹è¯•æ‰¹é‡ç”Ÿæˆ
    print("\n[æµ‹è¯•2] æ‰¹é‡Embedding")
    print("-" * 70)
    texts = [
        "N+1è¡¥å¿é‡‘å¦‚ä½•è®¡ç®—ï¼Ÿ",
        "åŠ³åŠ¨ä»²è£éœ€è¦å‡†å¤‡ä»€ä¹ˆææ–™ï¼Ÿ",
        "è¯•ç”¨æœŸè¢«è¾é€€æœ‰è¡¥å¿å—ï¼Ÿ",
        "å·¥ä½œå¹´é™æ€ä¹ˆç®—ï¼Ÿ",
        "æœˆå¹³å‡å·¥èµ„åŒ…æ‹¬å“ªäº›ï¼Ÿ"
    ]

    embeddings = client.embed_batch(texts, batch_size=5)
    print(f"\nç”Ÿæˆäº† {len(embeddings)} ä¸ªå‘é‡")

    # æµ‹è¯•ç›¸ä¼¼åº¦è®¡ç®—
    print("\n[æµ‹è¯•3] ç›¸ä¼¼åº¦è®¡ç®—")
    print("-" * 70)
    query = "å¦‚ä½•è®¡ç®—ç»æµè¡¥å¿é‡‘ï¼Ÿ"
    query_embedding = client.embed(query)

    print(f"æŸ¥è¯¢: {query}")
    print(f"\nä¸å„æ–‡æœ¬çš„ç›¸ä¼¼åº¦:")
    for i, text in enumerate(texts):
        similarity = client.cosine_similarity(query_embedding, embeddings[i])
        print(f"  {i+1}. {text}")
        print(f"     ç›¸ä¼¼åº¦: {similarity:.4f}")

    print("\n" + "=" * 70)
    print("âœ… æµ‹è¯•å®Œæˆ")


if __name__ == "__main__":
    main()
