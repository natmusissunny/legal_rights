"""
æ³•å¾‹ç»´æƒæ™ºèƒ½åŠ©æ‰‹ - CLIå…¥å£
"""
import argparse
import sys
import asyncio
from pathlib import Path

from .config import Config
from .env_loader import print_api_key_status


def main():
    """CLIä¸»å…¥å£"""
    parser = argparse.ArgumentParser(
        prog="python -m legal_rights",
        description="æ³•å¾‹ç»´æƒæ™ºèƒ½åŠ©æ‰‹ - ä¸“æ³¨äºç¦»èŒå‘˜å·¥åŠ³åŠ¨æ³•ç»´æƒé—®ç­”",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
ç¤ºä¾‹:
  # æ„å»ºçŸ¥è¯†åº“
  python -m legal_rights build-kb

  # å•æ¬¡é—®ç­”
  python -m legal_rights ask "å…¬å¸æ¶æ„è¾é€€ä¸ç»™è¡¥å¿æ€ä¹ˆåŠï¼Ÿ"

  # äº¤äº’å¼å¯¹è¯
  python -m legal_rights chat

  # æµ‹è¯•APIè¿æ¥
  python -m legal_rights test

  # æ˜¾ç¤ºçŸ¥è¯†åº“ç»Ÿè®¡
  python -m legal_rights stats
        """
    )

    subparsers = parser.add_subparsers(dest="command", help="å¯ç”¨å‘½ä»¤")

    # build-kb å‘½ä»¤
    parser_build = subparsers.add_parser(
        "build-kb",
        help="æ„å»ºçŸ¥è¯†åº“ï¼ˆæŠ“å–ç½‘é¡µã€ç”Ÿæˆæ–‡æ¡£ã€æ„å»ºå‘é‡ç´¢å¼•ï¼‰"
    )
    parser_build.add_argument(
        "--force",
        action="store_true",
        help="å¼ºåˆ¶é‡æ–°æ„å»ºï¼ˆå¿½ç•¥ç¼“å­˜ï¼‰"
    )
    parser_build.add_argument(
        "--skip-scrape",
        action="store_true",
        help="è·³è¿‡ç½‘é¡µæŠ“å–ï¼ˆä½¿ç”¨ç°æœ‰ç¼“å­˜ï¼‰"
    )

    # ask å‘½ä»¤
    parser_ask = subparsers.add_parser(
        "ask",
        help="å•æ¬¡é—®ç­”"
    )
    parser_ask.add_argument(
        "question",
        type=str,
        help="è¦æé—®çš„é—®é¢˜"
    )
    parser_ask.add_argument(
        "--verbose",
        action="store_true",
        help="æ˜¾ç¤ºè¯¦ç»†ä¿¡æ¯ï¼ˆåŒ…æ‹¬æ£€ç´¢çš„æ–‡æ¡£ç‰‡æ®µï¼‰"
    )
    parser_ask.add_argument(
        "--top-k",
        type=int,
        default=5,
        help="æ£€ç´¢æ–‡æ¡£æ•°é‡ï¼ˆé»˜è®¤5ï¼‰"
    )

    # chat å‘½ä»¤
    parser_chat = subparsers.add_parser(
        "chat",
        help="äº¤äº’å¼å¯¹è¯æ¨¡å¼"
    )
    parser_chat.add_argument(
        "--reset",
        action="store_true",
        help="æ¸…ç©ºå¯¹è¯å†å²é‡æ–°å¼€å§‹"
    )

    # test å‘½ä»¤
    parser_test = subparsers.add_parser(
        "test",
        help="æµ‹è¯•APIè¿æ¥"
    )

    # stats å‘½ä»¤
    parser_stats = subparsers.add_parser(
        "stats",
        help="æ˜¾ç¤ºçŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯"
    )

    args = parser.parse_args()

    # å¦‚æœæ²¡æœ‰æŒ‡å®šå‘½ä»¤ï¼Œæ˜¾ç¤ºå¸®åŠ©
    if not args.command:
        parser.print_help()
        sys.exit(0)

    # éªŒè¯é…ç½®
    if not Config.validate():
        print("\nâŒ é…ç½®éªŒè¯å¤±è´¥ï¼")
        print("\nè¯·æŒ‰ç…§ä»¥ä¸‹æ­¥éª¤é…ç½®APIå¯†é’¥ï¼š")
        print("1. å¤åˆ¶ .env.example ä¸º .env")
        print("2. åœ¨ .env æ–‡ä»¶ä¸­å¡«å…¥æ‚¨çš„ CLAUDE_API_KEY å’Œ OPENAI_API_KEY")
        print("\næˆ–è€…è®¾ç½®ç¯å¢ƒå˜é‡ï¼š")
        print("   export CLAUDE_API_KEY=your-claude-key")
        print("   export OPENAI_API_KEY=your-openai-key")
        print("\næç¤ºï¼šæŸ¥çœ‹ docs/SETUP_GUIDE.md è·å–è¯¦ç»†é…ç½®è¯´æ˜")
        sys.exit(1)

    # æ‰§è¡Œå‘½ä»¤
    try:
        if args.command == "build-kb":
            build_knowledge_base(force=args.force, skip_scrape=args.skip_scrape)
        elif args.command == "ask":
            ask_question(args.question, verbose=args.verbose, top_k=args.top_k)
        elif args.command == "chat":
            start_chat(reset=args.reset)
        elif args.command == "test":
            test_api_connection()
        elif args.command == "stats":
            show_stats()
    except KeyboardInterrupt:
        print("\n\nğŸ‘‹ å·²å–æ¶ˆ")
        sys.exit(0)
    except Exception as e:
        print(f"\nâŒ é”™è¯¯: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)


def build_knowledge_base(force: bool = False, skip_scrape: bool = False):
    """æ„å»ºçŸ¥è¯†åº“"""
    from .scraper import WebScraper, HTMLCleaner, ContentParser
    from .knowledge import TextGenerator, VectorIndexer

    print("\nğŸ—ï¸  å¼€å§‹æ„å»ºçŸ¥è¯†åº“")
    print("=" * 80)

    structured_contents = []

    # æ­¥éª¤1: ç½‘é¡µæŠ“å–
    if not skip_scrape:
        print("\n[æ­¥éª¤ 1/4] æŠ“å–ç½‘é¡µå†…å®¹")
        print("-" * 80)

        scraper = WebScraper()
        use_cache = not force

        try:
            results = asyncio.run(scraper.fetch_target_urls(use_cache=use_cache))

            if not any(results.values()):
                print("\nâš ï¸  æ‰€æœ‰ç½‘é¡µæŠ“å–å¤±è´¥")
                print("æç¤º: å¯èƒ½æ˜¯ç½‘ç«™åçˆ¬è™«ï¼Œè¯·æŸ¥çœ‹ scripts/manual_scrape_guide.md")
                print("æˆ–ä½¿ç”¨ --skip-scrape è·³è¿‡æŠ“å–æ­¥éª¤ï¼ˆä½¿ç”¨ç°æœ‰ç¼“å­˜ï¼‰")
                return

        except Exception as e:
            print(f"âŒ æŠ“å–å¤±è´¥: {e}")
            return
    else:
        print("\n[æ­¥éª¤ 1/4] è·³è¿‡ç½‘é¡µæŠ“å–ï¼ˆä½¿ç”¨ç¼“å­˜ï¼‰")
        print("-" * 80)
        print("âœ… å·²è·³è¿‡")

    # æ­¥éª¤2: å†…å®¹è§£æ
    print("\n[æ­¥éª¤ 2/4] è§£æå’Œæ¸…æ´—å†…å®¹")
    print("-" * 80)

    cleaner = HTMLCleaner()
    parser = ContentParser()

    # è¯»å–ç¼“å­˜çš„HTML
    cache_files = list(Config.CACHE_DIR.glob("*.html"))
    if not cache_files:
        print("âŒ æ²¡æœ‰æ‰¾åˆ°ç¼“å­˜çš„HTMLæ–‡ä»¶")
        print("è¯·å…ˆè¿è¡Œä¸å¸¦ --skip-scrape çš„å‘½ä»¤ï¼Œæˆ–æ‰‹åŠ¨æ·»åŠ HTMLåˆ° data/cache/")
        return

    print(f"æ‰¾åˆ° {len(cache_files)} ä¸ªç¼“å­˜æ–‡ä»¶")

    for i, cache_file in enumerate(cache_files, 1):
        print(f"\n  [{i}/{len(cache_files)}] {cache_file.name}")

        try:
            html = cache_file.read_text(encoding='utf-8')
            cleaned_html, text = cleaner.clean_and_extract(html)

            # å°è¯•ä»æ–‡ä»¶åæˆ–å†…å®¹æå–æ ‡é¢˜
            title = f"æ³•å¾‹æ–‡æ¡£ {i}"

            structured = parser.parse(
                html=cleaned_html,
                url=f"file://{cache_file}",
                title=title
            )

            structured_contents.append(structured)
            print(f"      âœ… è§£æå®Œæˆ ({len(structured.sections)} ä¸ªç« èŠ‚)")

        except Exception as e:
            print(f"      âŒ è§£æå¤±è´¥: {e}")

    if not structured_contents:
        print("\nâŒ æ²¡æœ‰æˆåŠŸè§£æä»»ä½•å†…å®¹")
        return

    print(f"\nâœ… æˆåŠŸè§£æ {len(structured_contents)} ä¸ªæ–‡æ¡£")

    # æ­¥éª¤3: ç”Ÿæˆæ–‡æ¡£
    print("\n[æ­¥éª¤ 3/4] ç”ŸæˆMarkdownæ–‡æ¡£")
    print("-" * 80)

    generator = TextGenerator()
    try:
        generator.generate_batch(structured_contents, format='md')
    except Exception as e:
        print(f"âŒ æ–‡æ¡£ç”Ÿæˆå¤±è´¥: {e}")
        return

    # æ­¥éª¤4: æ„å»ºå‘é‡ç´¢å¼•
    print("\n[æ­¥éª¤ 4/4] æ„å»ºå‘é‡ç´¢å¼•")
    print("-" * 80)

    try:
        indexer = VectorIndexer()
        indexer.build_index(structured_contents, show_progress=True)
        indexer.save_index()
    except Exception as e:
        print(f"âŒ ç´¢å¼•æ„å»ºå¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return

    # å®Œæˆ
    print("\n" + "=" * 80)
    print("ğŸ‰ çŸ¥è¯†åº“æ„å»ºå®Œæˆï¼")
    print("=" * 80)
    print("\nç°åœ¨å¯ä»¥ä½¿ç”¨ä»¥ä¸‹å‘½ä»¤:")
    print("  python -m legal_rights ask \"ä½ çš„é—®é¢˜\"")
    print("  python -m legal_rights chat")


def ask_question(question: str, verbose: bool = False, top_k: int = 5):
    """å•æ¬¡é—®ç­”"""
    from .agent import LegalAgent

    print("\nğŸ’¬ æ³•å¾‹ç»´æƒæ™ºèƒ½åŠ©æ‰‹")
    print("=" * 80)

    # æ£€æŸ¥ç´¢å¼•
    index_path = Config.VECTORS_DIR / "index.faiss"
    if not index_path.exists():
        print("\nâš ï¸  å‘é‡ç´¢å¼•ä¸å­˜åœ¨")
        print("è¯·å…ˆè¿è¡Œ: python -m legal_rights build-kb")
        return

    # åˆå§‹åŒ–Agent
    try:
        agent = LegalAgent()
    except Exception as e:
        print(f"âŒ Agentåˆå§‹åŒ–å¤±è´¥: {e}")
        return

    # é—®ç­”
    try:
        answer = agent.ask(question, use_context=False, top_k=top_k)

        # æ˜¾ç¤ºç­”æ¡ˆ
        print("\n" + "=" * 80)
        print(answer.display())

        # è¯¦ç»†æ¨¡å¼
        if verbose and answer.relevant_docs:
            print("\n" + "=" * 80)
            print("ğŸ“š ç›¸å…³æ–‡æ¡£ç‰‡æ®µ")
            print("=" * 80)

            for i, doc in enumerate(answer.relevant_docs, 1):
                print(f"\næ–‡æ¡£ {i}:")
                print(f"  ç« èŠ‚: {doc.section_title}")
                print(f"  å†…å®¹: {doc.content[:200]}...")

    except Exception as e:
        print(f"\nâŒ å›ç­”å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()


def start_chat(reset: bool = False):
    """äº¤äº’å¼å¯¹è¯"""
    from .agent import LegalAgent

    print("\nğŸ’¬ æ³•å¾‹ç»´æƒæ™ºèƒ½åŠ©æ‰‹ - äº¤äº’å¼å¯¹è¯")
    print("=" * 80)
    print("æç¤º:")
    print("  - è¾“å…¥é—®é¢˜å¹¶æŒ‰å›è½¦")
    print("  - è¾“å…¥ 'quit' æˆ– 'exit' é€€å‡º")
    print("  - è¾“å…¥ 'reset' é‡ç½®å¯¹è¯å†å²")
    print("  - è¾“å…¥ 'summary' æŸ¥çœ‹å¯¹è¯æ‘˜è¦")
    print("=" * 80)

    # æ£€æŸ¥ç´¢å¼•
    index_path = Config.VECTORS_DIR / "index.faiss"
    if not index_path.exists():
        print("\nâš ï¸  å‘é‡ç´¢å¼•ä¸å­˜åœ¨")
        print("è¯·å…ˆè¿è¡Œ: python -m legal_rights build-kb")
        return

    # åˆå§‹åŒ–Agent
    try:
        agent = LegalAgent()
    except Exception as e:
        print(f"âŒ Agentåˆå§‹åŒ–å¤±è´¥: {e}")
        return

    if reset:
        agent.reset_conversation()
        print("\nâœ… å¯¹è¯å†å²å·²é‡ç½®")

    print("\nå¼€å§‹å¯¹è¯...\n")

    turn = 0

    while True:
        try:
            # è·å–ç”¨æˆ·è¾“å…¥
            user_input = input(f"\n[{turn}] æ‚¨: ").strip()

            if not user_input:
                continue

            # ç‰¹æ®Šå‘½ä»¤
            if user_input.lower() in ['quit', 'exit', 'q']:
                print("\nğŸ‘‹ å†è§ï¼")
                break

            if user_input.lower() == 'reset':
                agent.reset_conversation()
                turn = 0
                print("âœ… å¯¹è¯å†å²å·²é‡ç½®")
                continue

            if user_input.lower() == 'summary':
                summary = agent.get_conversation_summary()
                print("\nğŸ“Š å¯¹è¯æ‘˜è¦:")
                print("-" * 80)
                print(summary)
                continue

            # é—®ç­”
            turn += 1
            print(f"\n[{turn}] åŠ©æ‰‹: ", end="", flush=True)

            answer = agent.chat(user_input)

            # æµå¼æ˜¾ç¤ºï¼ˆæ¨¡æ‹Ÿï¼‰
            print(answer.answer_text)

            # æ˜¾ç¤ºç½®ä¿¡åº¦
            if answer.confidence < 0.7:
                print(f"\nâš ï¸  ç½®ä¿¡åº¦è¾ƒä½ ({answer.confidence:.0%})ï¼Œå»ºè®®å’¨è¯¢ä¸“ä¸šå¾‹å¸ˆ")

        except KeyboardInterrupt:
            print("\n\nğŸ‘‹ å¯¹è¯å·²ç»“æŸ")
            break
        except Exception as e:
            print(f"\nâŒ é”™è¯¯: {e}")
            continue


def test_api_connection():
    """æµ‹è¯•APIè¿æ¥"""
    from .agent.llm_factory import create_llm_client
    from .knowledge.embedding_factory import create_embedding_client

    print("\nğŸ” æµ‹è¯•APIè¿æ¥")
    print("=" * 80)

    # æ˜¾ç¤ºAPIå¯†é’¥çŠ¶æ€
    print("\n[1] APIå¯†é’¥çŠ¶æ€")
    print("-" * 80)
    print_api_key_status()

    # æµ‹è¯• LLM API
    print("\n[2] æµ‹è¯• LLM API")
    print("-" * 80)

    try:
        llm_client = create_llm_client()
        print("æ­£åœ¨è°ƒç”¨LLM API...", end=" ", flush=True)

        response = llm_client.complete(
            prompt="è¯·ç”¨ä¸€å¥è¯è¯´æ˜ä»€ä¹ˆæ˜¯ç»æµè¡¥å¿é‡‘ã€‚",
            system="ä½ æ˜¯åŠ³åŠ¨æ³•å¾‹å¸ˆã€‚",
            temperature=0.5,
            max_tokens=100
        )

        print("âœ… æˆåŠŸ")
        print(f"å“åº”: {response[:100]}...")

    except Exception as e:
        print(f"âŒ å¤±è´¥")
        print(f"é”™è¯¯: {e}")

    # æµ‹è¯• Embedding API
    print("\n[3] æµ‹è¯• Embedding API")
    print("-" * 80)

    try:
        embedding_client = create_embedding_client()
        print("æ­£åœ¨ç”Ÿæˆå‘é‡...", end=" ", flush=True)

        embedding = embedding_client.embed("æµ‹è¯•æ–‡æœ¬")

        print("âœ… æˆåŠŸ")
        print(f"å‘é‡ç»´åº¦: {len(embedding)}")
        print(f"å‘é‡å‰5ç»´: {embedding[:5]}")

    except Exception as e:
        print(f"âŒ å¤±è´¥")
        print(f"é”™è¯¯: {e}")

    print("\n" + "=" * 80)
    print("æµ‹è¯•å®Œæˆ")


def show_stats():
    """æ˜¾ç¤ºçŸ¥è¯†åº“ç»Ÿè®¡"""
    import json

    print("\nğŸ“Š çŸ¥è¯†åº“ç»Ÿè®¡ä¿¡æ¯")
    print("=" * 80)

    # æ£€æŸ¥æ•°æ®ç›®å½•
    cache_dir = Config.CACHE_DIR
    knowledge_dir = Config.KNOWLEDGE_DIR
    vectors_dir = Config.VECTORS_DIR

    cache_files = list(cache_dir.glob("*.html")) if cache_dir.exists() else []
    doc_files = list(knowledge_dir.glob("*")) if knowledge_dir.exists() else []
    vector_files = list(vectors_dir.glob("*")) if vectors_dir.exists() else []

    print(f"\nğŸ“ æ•°æ®ç›®å½•:")
    print(f"  - ç¼“å­˜ç›®å½•: {cache_dir}")
    print(f"    HTMLæ–‡ä»¶: {len(cache_files)}")

    print(f"  - æ–‡æ¡£ç›®å½•: {knowledge_dir}")
    print(f"    Markdown: {len(list(knowledge_dir.glob('*.md')))}")
    print(f"    æ–‡æœ¬æ–‡ä»¶: {len(list(knowledge_dir.glob('*.txt')))}")

    print(f"  - å‘é‡ç›®å½•: {vectors_dir}")
    print(f"    æ–‡ä»¶æ•°: {len(vector_files)}")

    # è¯»å–å‘é‡ç»Ÿè®¡
    stats_file = vectors_dir / "stats.json"
    if stats_file.exists():
        print(f"\nğŸ“ˆ å‘é‡ç´¢å¼•ç»Ÿè®¡:")
        try:
            stats = json.loads(stats_file.read_text(encoding='utf-8'))
            print(f"  - æ–‡æ¡£æ•°: {stats.get('total_documents', 0)}")
            print(f"  - å‘é‡ç»´åº¦: {stats.get('vector_dimension', 0)}")
            print(f"  - ç´¢å¼•ç±»å‹: {stats.get('index_type', 'N/A')}")
            print(f"  - æ•°æ®æºæ•°: {len(stats.get('sources', []))}")
            print(f"  - ç« èŠ‚æ•°: {len(stats.get('sections', []))}")
        except Exception as e:
            print(f"  âš ï¸  è¯»å–ç»Ÿè®¡å¤±è´¥: {e}")

    # çŠ¶æ€åˆ¤æ–­
    print(f"\nğŸ¯ çŸ¥è¯†åº“çŠ¶æ€:")

    if len(cache_files) == 0:
        print("  âŒ æœªæŠ“å–ç½‘é¡µ")
        print("     è¿è¡Œ: python -m legal_rights build-kb")
    elif len(doc_files) == 0:
        print("  âš ï¸  å·²æŠ“å–ä½†æœªç”Ÿæˆæ–‡æ¡£")
        print("     è¿è¡Œ: python -m legal_rights build-kb --skip-scrape")
    elif len(vector_files) == 0:
        print("  âš ï¸  å·²ç”Ÿæˆæ–‡æ¡£ä½†æœªæ„å»ºç´¢å¼•")
        print("     è¿è¡Œ: python -m legal_rights build-kb --skip-scrape")
    else:
        print("  âœ… çŸ¥è¯†åº“å®Œæ•´")
        print("     å¯ä»¥ä½¿ç”¨: python -m legal_rights ask \"é—®é¢˜\"")


if __name__ == "__main__":
    main()
